---
permalink: trident-protect/monitor-trident-protect-resources.html 
sidebar: sidebar 
keywords: manage, authentication, rbac 
summary: È possibile monitorare lo stato delle risorse di protezione Trident utilizzando kube-state-metrics e Prometheus.  In questo modo vengono fornite informazioni sullo stato di implementazione, sui nodi e sui pod. 
---
= Monitora le risorse di protezione Trident
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
È possibile utilizzare gli strumenti open source kube-state-metrics, Prometheus e Alertmanager per monitorare lo stato di integrità delle risorse protette da Trident Protect.

Il servizio kube-state-metrics genera metriche dalla comunicazione API di Kubernetes.  Utilizzandolo con Trident Protect, puoi ottenere informazioni utili sullo stato delle risorse nel tuo ambiente.

Prometheus è un toolkit in grado di acquisire i dati generati da kube-state-metrics e presentarli come informazioni facilmente leggibili su questi oggetti.  Insieme, kube-state-metrics e Prometheus ti consentono di monitorare lo stato e l'integrità delle risorse che gestisci con Trident Protect.

Alertmanager è un servizio che acquisisce gli avvisi inviati da strumenti come Prometheus e li indirizza verso destinazioni configurate dall'utente.

[NOTE]
====
Le configurazioni e le istruzioni incluse in questi passaggi sono solo esempi; è necessario personalizzarle in base al proprio ambiente.  Per istruzioni e supporto specifici, fare riferimento alla seguente documentazione ufficiale:

* https://github.com/kubernetes/kube-state-metrics/tree/main["documentazione di kube-state-metrics"^]
* https://prometheus.io/docs/introduction/overview/["Documentazione di Prometheus"^]
* https://github.com/prometheus/alertmanager["Documentazione di Alertmanager"^]


====


== Passaggio 1: installare gli strumenti di monitoraggio

Per abilitare il monitoraggio delle risorse in Trident Protect, è necessario installare e configurare kube-state-metrics, Promethus e Alertmanager.



=== Installa kube-state-metrics

Puoi installare kube-state-metrics tramite Helm.

.Passi
. Aggiungere il grafico Helm kube-state-metrics. Per esempio:
+
[source, console]
----
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
----
. Applicare il CRD di Prometheus ServiceMonitor al cluster:
+
[source, console]
----
kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/example/prometheus-operator-crd/monitoring.coreos.com_servicemonitors.yaml
----
. Creare un file di configurazione per il grafico Helm (ad esempio, `metrics-config.yaml` ).  È possibile personalizzare la seguente configurazione di esempio in base al proprio ambiente:
+
.metrics-config.yaml: configurazione del grafico Helm kube-state-metrics
[source, yaml]
----
---
extraArgs:
  # Collect only custom metrics
  - --custom-resource-state-only=true

customResourceState:
  enabled: true
  config:
    kind: CustomResourceStateMetrics
    spec:
      resources:
      - groupVersionKind:
          group: protect.trident.netapp.io
          kind: "Backup"
          version: "v1"
        labelsFromPath:
          backup_uid: [metadata, uid]
          backup_name: [metadata, name]
          creation_time: [metadata, creationTimestamp]
        metrics:
        - name: backup_info
          help: "Exposes details about the Backup state"
          each:
            type: Info
            info:
              labelsFromPath:
                appVaultReference: ["spec", "appVaultRef"]
                appReference: ["spec", "applicationRef"]
rbac:
  extraRules:
  - apiGroups: ["protect.trident.netapp.io"]
    resources: ["backups"]
    verbs: ["list", "watch"]

# Collect metrics from all namespaces
namespaces: ""

# Ensure that the metrics are collected by Prometheus
prometheus:
  monitor:
    enabled: true
----
. Installa kube-state-metrics distribuendo il grafico Helm. Per esempio:
+
[source, console]
----
helm install custom-resource -f metrics-config.yaml prometheus-community/kube-state-metrics --version 5.21.0
----
. Configurare kube-state-metrics per generare metriche per le risorse personalizzate utilizzate da Trident Protect seguendo le istruzioni in https://github.com/kubernetes/kube-state-metrics/blob/main/docs/metrics/extend/customresourcestate-metrics.md#custom-resource-state-metrics["documentazione delle risorse personalizzate kube-state-metrics"^] .




=== Installa Prometheus

Puoi installare Prometheus seguendo le istruzioni nel https://prometheus.io/docs/prometheus/latest/installation/["Documentazione di Prometheus"^] .



=== Installa Alertmanager

Puoi installare Alertmanager seguendo le istruzioni nel https://github.com/prometheus/alertmanager?tab=readme-ov-file#install["Documentazione di Alertmanager"^] .



== Passaggio 2: configurare gli strumenti di monitoraggio affinché funzionino insieme

Dopo aver installato gli strumenti di monitoraggio, è necessario configurarli affinché funzionino insieme.

.Passi
. Integra kube-state-metrics con Prometheus.  Modifica il file di configurazione di Prometheus(`prometheus.yaml` ) e aggiungere le informazioni sul servizio kube-state-metrics. Per esempio:
+
.prometheus.yaml: integrazione del servizio kube-state-metrics con Prometheus
[source, yaml]
----
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: trident-protect
data:
  prometheus.yaml: |
    global:
      scrape_interval: 15s
    scrape_configs:
      - job_name: 'kube-state-metrics'
        static_configs:
          - targets: ['kube-state-metrics.trident-protect.svc:8080']
----
. Configurare Prometheus per indirizzare gli avvisi ad Alertmanager.  Modifica il file di configurazione di Prometheus(`prometheus.yaml` ) e aggiungere la seguente sezione:
+
.prometheus.yaml: Invia avvisi ad Alertmanager
[source, yaml]
----
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager.trident-protect.svc:9093
----


.Risultato
Prometheus ora può raccogliere metriche da kube-state-metrics e può inviare avvisi ad Alertmanager.  Ora sei pronto per configurare quali condizioni attivano un avviso e dove devono essere inviati gli avvisi.



== Passaggio 3: configurare gli avvisi e le destinazioni degli avvisi

Dopo aver configurato gli strumenti affinché funzionino insieme, è necessario configurare il tipo di informazioni che attivano gli avvisi e dove devono essere inviati.



=== Esempio di avviso: errore di backup

L'esempio seguente definisce un avviso critico che viene attivato quando lo stato della risorsa personalizzata di backup è impostato su `Error` per 5 secondi o più.  Puoi personalizzare questo esempio per adattarlo al tuo ambiente e includere questo frammento YAML nel tuo `prometheus.yaml` file di configurazione:

.rules.yaml: Definisci un avviso Prometheus per i backup non riusciti
[source, yaml]
----
rules.yaml: |
  groups:
    - name: fail-backup
        rules:
          - alert: BackupFailed
            expr: kube_customresource_backup_info{status="Error"}
            for: 5s
            labels:
              severity: critical
            annotations:
              summary: "Backup failed"
              description: "A backup has failed."
----


=== Configura Alertmanager per inviare avvisi ad altri canali

È possibile configurare Alertmanager per inviare notifiche ad altri canali, come e-mail, PagerDuty, Microsoft Teams o altri servizi di notifica specificando la rispettiva configurazione in `alertmanager.yaml` file.

L'esempio seguente configura Alertmanager per inviare notifiche a un canale Slack.  Per personalizzare questo esempio in base al tuo ambiente, sostituisci il valore di `api_url` chiave con l'URL del webhook Slack utilizzato nel tuo ambiente:

.alertmanager.yaml: invia avvisi a un canale Slack
[source, yaml]
----
data:
  alertmanager.yaml: |
    global:
      resolve_timeout: 5m
    route:
      receiver: 'slack-notifications'
    receivers:
      - name: 'slack-notifications'
        slack_configs:
          - api_url: '<your-slack-webhook-url>'
            channel: '#failed-backups-channel'
            send_resolved: false
----